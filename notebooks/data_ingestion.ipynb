{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51ba28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "import websockets\n",
    "import logging\n",
    "import datetime\n",
    "import pyais\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from psycopg2.extras import execute_values\n",
    "import argparse\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "import os\n",
    "from dataclasses import dataclass, asdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eb72435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"ais_receiver.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b59f7c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AISMessage:\n",
    "    \"\"\"Data class to store validated AIS message data\"\"\"\n",
    "    message_id: str\n",
    "    mmsi: int\n",
    "    timestamp: datetime.datetime\n",
    "    payload: str\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    speed: Optional[float] = None\n",
    "    course: Optional[float] = None\n",
    "    heading: Optional[float] = None\n",
    "    navigation_status: Optional[int] = None\n",
    "    message_type: Optional[int] = None\n",
    "    is_valid: bool = True\n",
    "    validation_errors: List[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.validation_errors is None:\n",
    "            self.validation_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0573ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AISMessage:\n",
    "    \"\"\"Data class to store validated AIS message data\"\"\"\n",
    "    message_id: str\n",
    "    mmsi: int\n",
    "    timestamp: datetime.datetime\n",
    "    payload: str\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    speed: Optional[float] = None\n",
    "    course: Optional[float] = None\n",
    "    heading: Optional[float] = None\n",
    "    navigation_status: Optional[int] = None\n",
    "    message_type: Optional[int] = None\n",
    "    is_valid: bool = True\n",
    "    validation_errors: List[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.validation_errors is None:\n",
    "            self.validation_errors = []\n",
    "\n",
    "class DataQualityMonitor:\n",
    "    \"\"\"Track data quality metrics for the ingestion pipeline\"\"\"\n",
    "    def __init__(self):\n",
    "        self.total_messages = 0\n",
    "        self.valid_messages = 0\n",
    "        self.invalid_messages = 0\n",
    "        self.duplicate_messages = 0\n",
    "        self.malformed_messages = 0\n",
    "        self.last_report_time = datetime.datetime.now()\n",
    "        self.report_interval = datetime.timedelta(minutes=5)\n",
    "        \n",
    "    def record_message(self, is_valid: bool, is_duplicate: bool = False, is_malformed: bool = False):\n",
    "        \"\"\"Record a processed message and its quality status\"\"\"\n",
    "        self.total_messages += 1\n",
    "        \n",
    "        if is_valid:\n",
    "            self.valid_messages += 1\n",
    "        else:\n",
    "            self.invalid_messages += 1\n",
    "            \n",
    "        if is_duplicate:\n",
    "            self.duplicate_messages += 1\n",
    "            \n",
    "        if is_malformed:\n",
    "            self.malformed_messages += 1\n",
    "            \n",
    "        # Generate periodic report\n",
    "        now = datetime.datetime.now()\n",
    "        if now - self.last_report_time > self.report_interval:\n",
    "            self._generate_report()\n",
    "            self.last_report_time = now\n",
    "    \n",
    "    def _generate_report(self):\n",
    "        \"\"\"Generate a data quality report\"\"\"\n",
    "        if self.total_messages == 0:\n",
    "            return\n",
    "            \n",
    "        valid_percent = (self.valid_messages / self.total_messages) * 100\n",
    "        \n",
    "        logger.info(f\"=== DATA QUALITY REPORT ===\")\n",
    "        logger.info(f\"Total messages processed: {self.total_messages}\")\n",
    "        logger.info(f\"Valid messages: {self.valid_messages} ({valid_percent:.2f}%)\")\n",
    "        logger.info(f\"Invalid messages: {self.invalid_messages}\")\n",
    "        logger.info(f\"Duplicate messages: {self.duplicate_messages}\")\n",
    "        logger.info(f\"Malformed messages: {self.malformed_messages}\")\n",
    "        logger.info(f\"===========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdbaa237",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseManager:\n",
    "    \"\"\"Manage database connections and operations\"\"\"\n",
    "    def __init__(self, host=\"localhost\", port=5432, dbname=\"ais_data\", \n",
    "                 user=\"postgres\", password=\"postgres\"):\n",
    "        self.connection_params = {\n",
    "            \"host\": host,\n",
    "            \"port\": port,\n",
    "            \"dbname\": dbname,\n",
    "            \"user\": user,\n",
    "            \"password\": password\n",
    "        }\n",
    "        self.conn = None\n",
    "        self.message_buffer = []\n",
    "        self.buffer_size = 100  # Batch inserts for performance\n",
    "        self.last_flush_time = datetime.datetime.now()\n",
    "        self.flush_interval = datetime.timedelta(seconds=5)\n",
    "        \n",
    "    def connect(self):\n",
    "        \"\"\"Establish connection to the database\"\"\"\n",
    "        try:\n",
    "            self.conn = psycopg2.connect(**self.connection_params)\n",
    "            logger.info(\"Connected to the database\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Database connection error: {e}\")\n",
    "            return False\n",
    "            \n",
    "    def initialize_database(self):\n",
    "        \"\"\"Create tables, indexes, and extensions if they don't exist\"\"\"\n",
    "        if not self.conn:\n",
    "            if not self.connect():\n",
    "                return False\n",
    "                \n",
    "        try:\n",
    "            with self.conn.cursor() as cur:\n",
    "                # Enable PostGIS extension\n",
    "                cur.execute(\"CREATE EXTENSION IF NOT EXISTS postgis;\")\n",
    "                \n",
    "                # Create AIS messages table\n",
    "                cur.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS ais_messages (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    message_id TEXT NOT NULL,\n",
    "                    mmsi INTEGER NOT NULL,\n",
    "                    timestamp TIMESTAMP WITH TIME ZONE NOT NULL,\n",
    "                    payload TEXT NOT NULL,\n",
    "                    latitude DOUBLE PRECISION NOT NULL,\n",
    "                    longitude DOUBLE PRECISION NOT NULL,\n",
    "                    speed DOUBLE PRECISION,\n",
    "                    course DOUBLE PRECISION,\n",
    "                    heading INTEGER,\n",
    "                    navigation_status INTEGER,\n",
    "                    message_type INTEGER,\n",
    "                    is_valid BOOLEAN DEFAULT TRUE,\n",
    "                    validation_errors TEXT[],\n",
    "                    geom GEOGRAPHY(POINT, 4326),\n",
    "                    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n",
    "                );\n",
    "                \"\"\")\n",
    "                \n",
    "                # Create vessel table for vessel metadata\n",
    "                cur.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS vessels (\n",
    "                    mmsi INTEGER PRIMARY KEY,\n",
    "                    first_seen TIMESTAMP WITH TIME ZONE,\n",
    "                    last_seen TIMESTAMP WITH TIME ZONE,\n",
    "                    message_count INTEGER DEFAULT 0\n",
    "                );\n",
    "                \"\"\")\n",
    "                \n",
    "                # Create indexes\n",
    "                cur.execute(\"CREATE INDEX IF NOT EXISTS idx_ais_messages_mmsi ON ais_messages(mmsi);\")\n",
    "                cur.execute(\"CREATE INDEX IF NOT EXISTS idx_ais_messages_timestamp ON ais_messages(timestamp);\")\n",
    "                cur.execute(\"CREATE INDEX IF NOT EXISTS idx_ais_messages_geom ON ais_messages USING GIST(geom);\")\n",
    "                \n",
    "                # Add unique constraint to prevent duplicates (same MMSI, timestamp, and location)\n",
    "                cur.execute(\"\"\"\n",
    "                CREATE UNIQUE INDEX IF NOT EXISTS idx_unique_message \n",
    "                ON ais_messages(mmsi, timestamp, latitude, longitude);\n",
    "                \"\"\")\n",
    "                \n",
    "                self.conn.commit()\n",
    "                logger.info(\"Database initialized successfully\")\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error initializing database: {e}\")\n",
    "            self.conn.rollback()\n",
    "            return False\n",
    "            \n",
    "    def store_message(self, message: AISMessage):\n",
    "        \"\"\"Store a single AIS message (adds to buffer)\"\"\"\n",
    "        self.message_buffer.append(message)\n",
    "        \n",
    "        now = datetime.datetime.now()\n",
    "        if len(self.message_buffer) >= self.buffer_size or \\\n",
    "           (now - self.last_flush_time) > self.flush_interval:\n",
    "            self.flush_buffer()\n",
    "            \n",
    "    def flush_buffer(self):\n",
    "        \"\"\"Flush the message buffer to the database\"\"\"\n",
    "        if not self.message_buffer:\n",
    "            return\n",
    "            \n",
    "        if not self.conn:\n",
    "            if not self.connect():\n",
    "                logger.error(\"Cannot flush buffer: no database connection\")\n",
    "                return\n",
    "                \n",
    "        try:\n",
    "            with self.conn.cursor() as cur:\n",
    "                # Insert messages\n",
    "                values = []\n",
    "                for msg in self.message_buffer:\n",
    "                    values.append((\n",
    "                        msg.message_id,\n",
    "                        msg.mmsi,\n",
    "                        msg.timestamp,\n",
    "                        msg.payload,\n",
    "                        msg.latitude,\n",
    "                        msg.longitude,\n",
    "                        msg.speed,\n",
    "                        msg.course,\n",
    "                        msg.heading,\n",
    "                        msg.navigation_status,\n",
    "                        msg.message_type,\n",
    "                        msg.is_valid,\n",
    "                        msg.validation_errors if msg.validation_errors else None,\n",
    "                        f\"POINT({msg.longitude} {msg.latitude})\"\n",
    "                    ))\n",
    "                \n",
    "                execute_values(cur, \"\"\"\n",
    "                INSERT INTO ais_messages \n",
    "                (message_id, mmsi, timestamp, payload, latitude, longitude, \n",
    "                 speed, course, heading, navigation_status, message_type, \n",
    "                 is_valid, validation_errors, geom)\n",
    "                VALUES %s\n",
    "                ON CONFLICT (mmsi, timestamp, latitude, longitude) DO NOTHING\n",
    "                \"\"\", values, template=\"(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, ST_GeographyFromText(%s))\")\n",
    "                \n",
    "                # Update vessel stats\n",
    "                mmsi_values = [(msg.mmsi, msg.timestamp, msg.timestamp) for msg in self.message_buffer]\n",
    "                execute_values(cur, \"\"\"\n",
    "                INSERT INTO vessels (mmsi, first_seen, last_seen, message_count)\n",
    "                VALUES %s\n",
    "                ON CONFLICT (mmsi) DO UPDATE SET\n",
    "                  first_seen = LEAST(vessels.first_seen, EXCLUDED.first_seen),\n",
    "                  last_seen = GREATEST(vessels.last_seen, EXCLUDED.last_seen),\n",
    "                  message_count = vessels.message_count + 1\n",
    "                \"\"\", mmsi_values, template=\"(%s, %s, %s, 1)\")\n",
    "                \n",
    "                self.conn.commit()\n",
    "                logger.info(f\"Flushed {len(self.message_buffer)} messages to database\")\n",
    "                self.message_buffer = []\n",
    "                self.last_flush_time = datetime.datetime.now()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error flushing message buffer: {e}\")\n",
    "            self.conn.rollback()\n",
    "            \n",
    "    def close(self):\n",
    "        \"\"\"Close database connection\"\"\"\n",
    "        if self.conn:\n",
    "            self.flush_buffer()  # Ensure all buffered messages are written\n",
    "            self.conn.close()\n",
    "            logger.info(\"Database connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82acebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AISProcessor:\n",
    "    \"\"\"Process AIS messages from WebSocket and validate them\"\"\"\n",
    "    def __init__(self, db_manager: DatabaseManager):\n",
    "        self.db_manager = db_manager\n",
    "        self.quality_monitor = DataQualityMonitor()\n",
    "        \n",
    "    def decode_ais_payload(self, payload: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Decode AIS message payload using pyais\"\"\"\n",
    "        try:\n",
    "            # Remove the leading '!' and trailing checksum if present\n",
    "            if payload.startswith('!'):\n",
    "                payload = payload[1:]\n",
    "                \n",
    "            if ',' in payload:\n",
    "                parts = payload.split(',')\n",
    "                if len(parts) >= 6:  # Typical AIVDM/AIVDO message format\n",
    "                    message = pyais.decode(payload)\n",
    "                    return message.asdict()\n",
    "                    \n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error decoding AIS payload: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def validate_ais_message(self, data: Dict[str, Any]) -> Tuple[bool, List[str]]:\n",
    "        \"\"\"Validate AIS message and return (is_valid, error_list)\"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        # Check MMSI is valid\n",
    "        if 'mmsi' not in data or not isinstance(data['mmsi'], int) or data['mmsi'] <= 0:\n",
    "            errors.append(\"Invalid MMSI number\")\n",
    "            \n",
    "        # Check coordinates are valid\n",
    "        if 'lat' not in data or 'lon' not in data:\n",
    "            errors.append(\"Missing coordinates\")\n",
    "        elif not (-90 <= data.get('lat', 0) <= 90):\n",
    "            errors.append(f\"Invalid latitude: {data.get('lat')}\")\n",
    "        elif not (-180 <= data.get('lon', 0) <= 180):\n",
    "            errors.append(f\"Invalid longitude: {data.get('lon')}\")\n",
    "            \n",
    "        # Ensure minimum required fields are present\n",
    "        for field in ['msg_type']:\n",
    "            if field not in data:\n",
    "                errors.append(f\"Missing required field: {field}\")\n",
    "                \n",
    "        return len(errors) == 0, errors\n",
    "        \n",
    "    async def process_message(self, raw_message: str):\n",
    "        \"\"\"Process a raw WebSocket message\"\"\"\n",
    "        try:\n",
    "            # Parse the WebSocket message\n",
    "            message_data = json.loads(raw_message)\n",
    "            \n",
    "            # Get required fields\n",
    "            mmsi = message_data.get('mmsi')\n",
    "            timestamp_str = message_data.get('timestamp')\n",
    "            payload = message_data.get('payload')\n",
    "            \n",
    "            if not all([mmsi, timestamp_str, payload]):\n",
    "                logger.warning(f\"Missing required fields in message: {raw_message}\")\n",
    "                self.quality_monitor.record_message(False, is_malformed=True)\n",
    "                return\n",
    "                \n",
    "            # Convert timestamp\n",
    "            try:\n",
    "                timestamp = datetime.datetime.fromisoformat(timestamp_str)\n",
    "            except ValueError:\n",
    "                logger.warning(f\"Invalid timestamp format: {timestamp_str}\")\n",
    "                timestamp = datetime.datetime.now()\n",
    "            \n",
    "            # Handle single payload or list of payloads\n",
    "            if isinstance(payload, list):\n",
    "                payload_str = payload[0]\n",
    "            else:\n",
    "                payload_str = payload\n",
    "                \n",
    "            # Decode AIS data\n",
    "            decoded_data = self.decode_ais_payload(payload_str)\n",
    "            \n",
    "            if not decoded_data:\n",
    "                logger.warning(f\"Failed to decode AIS payload: {payload_str}\")\n",
    "                self.quality_monitor.record_message(False, is_malformed=True)\n",
    "                return\n",
    "                \n",
    "            # Validate the decoded data\n",
    "            is_valid, validation_errors = self.validate_ais_message(decoded_data)\n",
    "            \n",
    "            # Create AIS message object\n",
    "            ais_message = AISMessage(\n",
    "                message_id=f\"{mmsi}_{timestamp.isoformat()}\",\n",
    "                mmsi=mmsi,\n",
    "                timestamp=timestamp,\n",
    "                payload=payload_str,\n",
    "                latitude=decoded_data.get('lat', 0.0),\n",
    "                longitude=decoded_data.get('lon', 0.0),\n",
    "                speed=decoded_data.get('speed', None),\n",
    "                course=decoded_data.get('course', None),\n",
    "                heading=decoded_data.get('heading', None),\n",
    "                navigation_status=decoded_data.get('status', None),\n",
    "                message_type=decoded_data.get('msg_type', None),\n",
    "                is_valid=is_valid,\n",
    "                validation_errors=validation_errors\n",
    "            )\n",
    "            \n",
    "            # Record quality metrics\n",
    "            self.quality_monitor.record_message(is_valid)\n",
    "            \n",
    "            # Store in database\n",
    "            self.db_manager.store_message(ais_message)\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            logger.error(f\"Invalid JSON in message: {raw_message}\")\n",
    "            self.quality_monitor.record_message(False, is_malformed=True)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing message: {e}\")\n",
    "            self.quality_monitor.record_message(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de50b290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--websocket-uri WEBSOCKET_URI]\n",
      "                             [--db-host DB_HOST] [--db-port DB_PORT]\n",
      "                             [--db-name DB_NAME] [--db-user DB_USER]\n",
      "                             [--db-password DB_PASSWORD]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\Abhinesh\\AppData\\Roaming\\jupyter\\runtime\\kernel-v35c1ad67731a15849a268b51aa8d8231c83b60caf.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "async def websocket_client(uri: str, processor: AISProcessor):\n",
    "    \"\"\"Connect to WebSocket server and process messages\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            async with websockets.connect(uri) as websocket:\n",
    "                logger.info(f\"Connected to {uri}\")\n",
    "                \n",
    "                while True:\n",
    "                    message = await websocket.recv()\n",
    "                    logger.debug(f\"Received message: {message}\")\n",
    "                    await processor.process_message(message)\n",
    "        except websockets.ConnectionClosed:\n",
    "            logger.warning(\"WebSocket connection closed, attempting to reconnect...\")\n",
    "            await asyncio.sleep(5)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"WebSocket error: {e}\")\n",
    "            await asyncio.sleep(5)\n",
    "\n",
    "async def main(websocket_uri: str, db_config: Dict[str, Any]):\n",
    "    \"\"\"Main application entry point\"\"\"\n",
    "    db_manager = DatabaseManager(\n",
    "        host=db_config['host'],\n",
    "        port=db_config['port'],\n",
    "        dbname=db_config['dbname'],\n",
    "        user=db_config['user'],\n",
    "        password=db_config['password']\n",
    "    )\n",
    "    \n",
    "    if not db_manager.connect():\n",
    "        logger.error(\"Failed to connect to database. Exiting.\")\n",
    "        return\n",
    "        \n",
    "    if not db_manager.initialize_database():\n",
    "        logger.error(\"Failed to initialize database. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    processor = AISProcessor(db_manager)\n",
    "    \n",
    "    try:\n",
    "        await websocket_client(websocket_uri, processor)\n",
    "    except KeyboardInterrupt:\n",
    "        logger.info(\"Shutting down...\")\n",
    "    finally:\n",
    "        db_manager.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"AIS Data Receiver\")\n",
    "    parser.add_argument(\"--websocket-uri\", default=\"ws://localhost:8765\", \n",
    "                      help=\"WebSocket server URI\")\n",
    "    parser.add_argument(\"--db-host\", default=\"localhost\", help=\"Database host\")\n",
    "    parser.add_argument(\"--db-port\", type=int, default=5432, help=\"Database port\")\n",
    "    parser.add_argument(\"--db-name\", default=\"ais_data\", help=\"Database name\")\n",
    "    parser.add_argument(\"--db-user\", default=\"postgres\", help=\"Database user\")\n",
    "    parser.add_argument(\"--db-password\", default=\"postgres\", help=\"Database password\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    db_config = {\n",
    "        \"host\": args.db_host,\n",
    "        \"port\": args.db_port,\n",
    "        \"dbname\": args.db_name,\n",
    "        \"user\": args.db_user,\n",
    "        \"password\": args.db_password\n",
    "    }\n",
    "    \n",
    "    asyncio.run(main(args.websocket_uri, db_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f293e646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blurgs_de",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
